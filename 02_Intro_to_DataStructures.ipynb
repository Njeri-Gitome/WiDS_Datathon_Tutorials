{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Introduction to Data Structures\n",
    "\n",
    "In this tutorial, we will explore the different structures we can use to capture and represent data; learn to import, access the documentation of, and use important data science tools; and walk through some exercises that will help us to begin to interpret what the collections of data points can tell us.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "**1. [Importing Python Packages](#packages)**  \n",
    "**2. [Sequences](#seq)**  \n",
    "&ensp;&ensp;&ensp;&ensp;**2.1.** [Lists](#list)  \n",
    "&ensp;&ensp;&ensp;&ensp;**2.2.** [Sequence Iteration](#iter)     \n",
    "&ensp;&ensp;&ensp;&ensp;**2.3.** [Arrays](#array)     \n",
    "&ensp;&ensp;&ensp;&ensp;**2.4.** [Strings](#str)    \n",
    "**3. [Summary Statistics](#stats)**     \n",
    "&ensp;&ensp;&ensp;&ensp;**3.1.** [Percentiles](#percentile)  \n",
    "&ensp;&ensp;&ensp;&ensp;**3.2.** [The Mean](#mean)    \n",
    "&ensp;&ensp;&ensp;&ensp;**3.3.** [Standard Deviation](#stddev)   \n",
    "**4. [More Data Structures](#struct)**   \n",
    "&ensp;&ensp;&ensp;&ensp;**4.1.** [Dictionaries](#dict)  \n",
    "&ensp;&ensp;&ensp;&ensp;**4.2.** [Matrices](#matrix)  \n",
    "**5. [Pandas Library](#pd)**  \n",
    "&ensp;&ensp;&ensp;&ensp;**5.1.** [Reading in Data](#import)  \n",
    "&ensp;&ensp;&ensp;&ensp;**5.2.** [Data Frames](#df)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>1. Importing Python Packages</u><a id='packages'></a>\n",
    "---\n",
    "\n",
    "In the last tutorial, we learned how to define our own functions. But writing functions is time-consuming, and much of the statistical and data wrangling operations we need have already been written for us by someone else. Rather than reinventing the wheel, it is much more efficient to leverage code that already exist. Further, rather than copying raw code into our notebooks, we can import what are called **Python modules, packages, and libraries** straight into Jupyter Notebooks. Python modules are Python files that contain the code for functions; once imported, they allow us to call upon the function names defined in the file. Python packages and libraries are just larger collections of Python modules, and can be leveraged in much the same way.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Run the cell below to import the NumPy library:</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell!\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import entire modules, which give us access to all the functions and tools contained in that module. But when we do, we must reference the name of the module every time we want to access its contents, as follows:  \n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "    <div class=\"alert alert-warning col-md-5\" align=\"center\"><code>&lt;module_name&gt;.&lt;function_name&gt;</code></div>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "This is why we tend to assign an abbreviated name during these full imports. Doing so makes calling on the source easier and less verbose:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without \"as np\" in the import statement, we would need to write \"numpy.e\"\n",
    "np.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling on the \"round\" function from the numpy library\n",
    "# rounding Euler's number (e) to the third decimal place \n",
    "np.round(np.e, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, if we know we only want a specific item from a given module, we can choose to import just that item from the module. We do this in the second import statement, where we import just the constant value `pi` from the `math` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell!\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can call this constant as is, because we specifically imported this.\n",
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have just seen, modules can provide not just functions but special values, too - values like `pi` and `e`. These values from modules are called **constants**. To find further information on other capabilities offered by Python modules and instructions on how to use them, a quick Google search should take you to the tools' detailed documentation sites. These docs are fantastic resources for when you are looking for the right tool to use, or when you need guidance on how to use a specific function. Check out the docs for the NumPy library [here](https://numpy.org/doc/stable/reference/index.html), or for the Python math module [here](https://docs.python.org/3/library/math.html)!\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<i class=\"fa fa-info-circle\" style=\"font-size:22px;color:orange\"></i> &nbsp;<b><u>Tip: </u></b><br>Sometimes we just want quick access to a function's docstrings, for instance to check for its expected arguments. In the Jupyter Notebook, we can access this by adding a <code>?</code> at the end of a function in a code cell, and running the cell. While not as detailed as the official reference sites, this can be a convenient way to recall how to use a function.<br><br><b>Run the code below to see the doctring for NumPy's <code>round()</code> function we used above:</b></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will load the docstring for the function! \n",
    "np.round?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy will become incredibly useful to us in a bit - it is known for its efficient processing capabilities of **arrays**, which are collections of homogeneous data points. We'll get more into arrays very shortly!\n",
    "\n",
    "---\n",
    "\n",
    "## <u>2. Sequences</u><a id='seq'></a>\n",
    "\n",
    "In the last tutorial, we introduced different types of values such as integers (e.g. `1`), strings (e.g. `'one'`), and booleans (e.g. `True`). This tutorial is all about the different ways in which we can collect and work with a bunch of data points in an organized form; and creating sequences of data is a great way to do just that.\n",
    "\n",
    "<br>\n",
    "\n",
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "A <b><u>sequence</u></b> is a collection of values that:\n",
    "- contains a finite number of elements (values). <br>&ensp;*The number of elements in a sequence determines its <b>length</b>.*\n",
    "- is <b>ordered</b>. <br>&ensp;*The order in which the elements appear in the sequence does not change unless intentionally changed.*\n",
    "- supports <b>element selection</b>. <br>&ensp;*Any element can be identified from the sequence based on its position, also known as its index, in the sequence.*</div>\n",
    "\n",
    "Sequences can take many forms. In this tutorial, we will touch on three the most commonly used ones -  **lists**, **arrays**, and - that's right - **strings**!\n",
    "\n",
    "_**Lists:**_  \n",
    "```python\n",
    "ex. [1, 2, 3, 4, 5]\n",
    "```\n",
    "_**Arrays:**_  \n",
    "```python\n",
    "ex. array([1, 2, 3, 4, 5])\n",
    "```\n",
    "_**Strings:**_\n",
    "```python\n",
    "ex. 'hello world' \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.1. Lists<a id='list'></a>\n",
    "\n",
    "The `list` value is a very powerful, fundamental sequence that has a large set of built-in behaviors for modifying and manipulating the list. We will cover only the basics here, but feel free to [explore its other features on your own](https://python-reference.readthedocs.io/en/latest/docs/list/).\n",
    "\n",
    "First, let's create one. Lists are formed by placing a comma-separated list of values or expressions in square `[]` brackets. `my_list` is a list of four values - since it contains four integers, it has a length of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [2020, 2021, 2022, 2023]\n",
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm the length of the list by using the built-in function, `len()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to call other functions on this group of numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the NumPy function, `median`\n",
    "np.median(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-warning\"><b><i class=\"fa fa-info-circle\" style=\"font-size:22px;color:orange\"></i> &nbsp;An important feature of a list</b> is that it can hold any collection of elements - they do not all need to be the same data type.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_list = [1996, '1997', 1998, True]\n",
    "another_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; <b>Indexing:</b>  \n",
    "\n",
    "One of the requirements of a sequence is that we be able to identify an element based on its position in the sequence. As we mentioned earlier, an element's position in a sequence is called its **index**. An index is a non-negative integer that indicates where an element is from the very front of the sequence. It is important to note that, in Python, the **index starts at 0**: the first element has an index of 0, the second element has index 1, the third element has index 2, and so on...\n",
    "\n",
    "```\n",
    "my_list: [2020, 2021, 2022, 2023]\n",
    "  index: (   0,    1,    2,    3)\n",
    "```\n",
    "\n",
    "If we know the index we want to select from a list, we can do so by putting it in square brackets next to the list itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the first element of `my_list`\n",
    "my_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Question: What would you expect the following to output?</b></span></div>\n",
    "\n",
    "```python\n",
    "my_list[4]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your theory here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; <b>Slicing:</b>  \n",
    "\n",
    "We can also create a sub-list of specific ranges of elements in a list - we call this slicing. We do this in a similar square bracket notation, but rather than specifing one index to select, we specify a start index, stop index, and (optionally) a step value: `[start:stop:step]`.\n",
    "\n",
    "In \"ex.1\" below, we specify a `start` index at 0 and `stop` index at 3. We don't specify a `step` value, so the function defaults it to 1. This means that the function will create a list of all elements positioned at indices **0, 1, and 2**: in other words, indices starting at 0 and incremented by 1 until we reach the stop index of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex.1\n",
    "my_list[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the element at the `stop` index is not selected. That is because ranges in Python usually exclude the index at the `stop` position from selection.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Question: What would you expect the following to output?</b></span></div>\n",
    "\n",
    "```python\n",
    "my_list[0:3:2]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your theory here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; <b>Operators:</b>  \n",
    "\n",
    "We can combine numbers and strings using operators like `+` and `*`. However, instead of operating on the values contained in the list, these operations combine and replicate the sequences themselves. For instance, **adding** two lists together will **concatenate** them - in other words, it would create one long list containing all elements from both lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list + another_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the order of elements is maintained, such that the elements of `my_list` appear first and elements of `another_list` appear second. \n",
    "\n",
    "Lists can only be added to other lists. See what happens when you try to add another integer to a list: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will error\n",
    "my_list + 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will work\n",
    "my_list + [2025]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't add a scalar value to a list, but we can **multiply** a list with a scalar `s` to create a new list containing elements of the original list replicated `s` times. Arithmetically, this makes sense because multiplying a list by `s` is equivalent to adding `s` copies of the list to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 3\n",
    "my_list * s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2. Sequence Iteration<a id='iter'></a>  \n",
    "We have just seen that applying arithmetic operations to a list doesn't alter the value of the elements contained within the list. In order to access and alter the values themselves, we must **loop through** the sequence of elements, apply the alteration to the individual values, and populate a new list with these changed values. This section will cover two ways in which we can do this.\n",
    "\n",
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; <b>For-Loops:</b>\n",
    "\n",
    "We can loop through iterable objects, like sequences, using the **`for`**-statement, also known as the **`for`**-loop.  \n",
    "The syntax for the `for`-loop is as follows:\n",
    "\n",
    "```python\n",
    "for <element> in <some_sequence>:\n",
    "    <process_to_execute>\n",
    "```\n",
    "><div class=\"alert alert-warning\">\n",
    "<b>In plain language:</b>  <br>\n",
    "&nbsp;&nbsp;&nbsp; \"<b>for</b> each individual <b>element</b> contained <b>in</b> the <b>list</b>, execute the specified <b>process</b>.\"<br><br>It is important to note that the <code>&lt;process_to_execute&gt;</code> is only focused on one element at a time. In the order that they appear in the original list, the loop is essentially picking up one element from the list, performing whatever set of instructions it is provided, and setting it down before picking up the next element, executing the same instructions, putting it down, and repeating the process until there are no more elements left to pick up.\n",
    "</div>\n",
    "\n",
    "Below is a simple for-loop that prints the value of each element in `my_list`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in my_list:\n",
    "    print(\"value: \", year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of `year` as a <u>temporary</u> variable that gets set to the value of whatever element is currently being \"picked up\" during the iteration.\n",
    "\n",
    "If we want to change the values of the list and save them in a new list, we can **initiate a new, empty list**, and add the changed values to the new list as we loop through the original list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop 1:\n",
    "# creating a new empty list\n",
    "new_list = []\n",
    "\n",
    "# looping through my_list, adding 10 to each year, & saving in the new list\n",
    "for year in my_list:\n",
    "    new_list = new_list + [year+10]\n",
    "    \n",
    "new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had mentioned that lists have many useful built-in behaviors. We leverage one of them below to achieve the same outcome, using its **`.append()` method**, to throw in a new value at the end of the list.\n",
    "\n",
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**<div class=\"alert alert-success\">\n",
    "A <b>method</b> is like a function, but it is a feature of another object that is called using the dot <code>.</code> notation on the object itself.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop 2:\n",
    "# another way to achieve the same thing\n",
    "# using the `append` method of lists\n",
    "new_list = []\n",
    "for year in my_list:\n",
    "    new_list.append(year+10)\n",
    "    \n",
    "new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although they achieve the same outcome, there is an important difference between loop 1 and loop 2:  \n",
    "* <u><b>loop 1:</b></u><br>The expression `new_list + [year+10]` outputs an entirely **new list** - this expression alone does **not** change the contents of the variable `new_list`. For this reason, we must reassign `new_list` to the result of the expression.\n",
    "<br>\n",
    "\n",
    "* <u><b>loop 2:</b></u><br>The `.append()` method called on `new_list` alters the list itself. Unlike the arithmetic operation in loop 1 that outputs a new list, this expression does not output anything - the result of this expression is simply that `new_list` now contains the new value. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Conditions in For-Loops:**\n",
    "\n",
    "We can specify certain values in the list to be handled differently than others. In the example below, we employ conditional statements to accomplish the following: **add 10** to every **even year**, and **subtract 10** from every **odd year**.\n",
    "\n",
    "*Note: recall that `%` (modulo operator) computes the remainder of dividing the value on the left-hand side by the value on the right-hand side. A number `X` is even if `X / 2` has reaminder of 0 - in other words, `X%2==0`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for year in my_list:\n",
    "    if year%2==0:\n",
    "        new_list.append(year+10)\n",
    "    else:\n",
    "        new_list.append(year-10)\n",
    "\n",
    "# showing contents of new list\n",
    "new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; <b>List Comprehension:</b>  \n",
    "\n",
    "A nicer way to create a new list of transformed values is with a **list comprehension**, which iterates through an interable, applies transformations to values, and collects the new values in list - all in one line of code:\n",
    "\n",
    "```python\n",
    "[function(element) for element in my_list]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 10 years to each element in my_list\n",
    "new_list = [year+10 for year in my_list]\n",
    "new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also posible to introduce conditionals in a list comprehension:\n",
    "\n",
    "```python\n",
    "[function_1(element) if condition_1 else function_2(element) for element in my_list]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 10 to even years, subtract 10 from odd years\n",
    "new_list = [year+10 if year%2==0 else year-10 for year in my_list]\n",
    "new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.3. Arrays<a id='array'></a>\n",
    "\n",
    "An array is structurally very similar to a list in that it is another sequence for containing data values, but arrays are different in a few key ways that often make them the preferred container for storing and handling data.\n",
    "\n",
    "<br>\n",
    "\n",
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">  \n",
    "An <b><u>array</u></b> is a sequence. It is an ordered collection of a finite number of values, similar to a list but different in that:  \n",
    "\n",
    "- the elements in an array <b>must all be of the same data type</b>, and\n",
    "- arrays can be <b>operated on arithmetically with much more versatility</b> than regular lists\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; <b>Creating an Array</b>  \n",
    "\n",
    "Let's create our first array to take a deeper dive at its characteristics. We will be accessing arrays from a Python library we imported in the last section - NumPy.\n",
    "\n",
    "We can create an array from the list we made earlier, by calling `np.array()` - this function takes any sequence and turns it into an array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.array(my_list)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the array assumes we want to maintain the data type of the elements in the original list. This is possible here because `my_list` is a list of integer values only. We can also instruct the function to take `my_list` and create an array containing strings rather than integers, using the data-type (`dtype`) parameter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the desired data-type for the array\n",
    "np.array(my_list, dtype= str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to create an array from a list that contains different value types, the function will try and find the easiest way to assign a data type that can capture all the elements as a single data type. If we try to create an array from `another_list`, the function will capture the elements as strings by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_array = np.array(another_list)\n",
    "another_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; <b>Indexing & Slicing</b>\n",
    "\n",
    "Selecting elements from an array and slicing arrays work just the same way as they do with lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the 4th element in the array\n",
    "my_array[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing\n",
    "my_array[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; <b>Creating a Range of values with <code>np.arange()</code></b>  \n",
    "\n",
    "There will be times when we want to create an evenly incremented numeric array. `np.arange()` lets us do just that, using a very similar approach of specifying `start`, `stop`, and `step` arguments that we've seen in the context of slicing.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Run the code below to pull up the docstrings for <code>np.arange()</code>:</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>You Try!</b> Based on the instructions from the documentation, can you use the function to create the following three arrays?</span></div>\n",
    "\n",
    "```\n",
    "1. array([0, 1, 2, 3, 4])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2. array([12, 19, 26, 33, 40, 47, 54, 61, 68, 75, 82, 89, 96])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "3. array([3. , 3.5, 4. , 4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. ])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; <b>Arithmetic Operations</b>  \n",
    "\n",
    "Recall that when we executed arithmetic operations with lists, they had the effect of combining and replicating the sequence itself but not the values contained within the sequence. In order to alter the values themselves, we needed to loop through the list, apply a transformation to each individual value, and store it back in a list.\n",
    "\n",
    "With arrays, we are able to transform the values contained within it using very simple arithmetic operations. If we want to add 10 to each value in an array, we would simply write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array+10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike lists, arrays apply arithmetic operations to the elements contained within. This makes it very easy, for instance, to convert the units of the values of an array.\n",
    "\n",
    "In the example below, we create the array `highs` that capture the average daily high temperatures (&deg;C) for the decades surrounding 1850, 1900, 1950, and 2000. The following operation converts the units of all of these temperatures to Fahrenheit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highs = np.array([13.6, 14.387, 14.585, 15.164])\n",
    "\n",
    "(9/5) * highs + 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./images/highs.PNG\" width=\"600\" height=\"800\" align='left'>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With lists, we saw that adding two lists together creates a longer list containing all elements from the added lists. You may be wondering what happens when you add two arrays together.\n",
    "\n",
    "Let's define another array - `lows` - that capture the average daily **low** temperatures for the decades surrounding 1850, 1900, 1950, and 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lows = np.array([2.128, 2.371, 2.874, 3.728])\n",
    "lows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to find the average daily range of temperatures for each decade. Then we could simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highs - lows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/arrays2.PNG\" width=\"500\" height=\"800\" align='left'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<i class=\"fa fa-info-circle\" style=\"font-size:22px;color:orange\"></i> &nbsp;\n",
    "    If an arithmetic operator acts on two arrays <b>of the same size</b>, then the operation is performed on each corresponding pair of elements in the two arrays. The final result is an array.<br><br>\n",
    "If the arrays do not contain the same number of elements, the operation will fail. <b>Run the cell below to see what happens when an array with only 3 elements are subtracted from the <code>highs</code> array:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will throw an error\n",
    "lows_only3 = np.array([2.128, 2.371, 2.874])\n",
    "highs - lows_only3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4. Strings  <a id='str'></a>\n",
    "\n",
    "It's worth mentioning that a string is another data type that is also a sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1. Strings contain a finite number of characters, and thus have a **length**:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2. Strings are **ordered**:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the order of characters in the string will not change\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3. Strings support **element selection**:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet[2] + alphabet[14]*2 + alphabet[11] + '!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can iterate through a string in a loop, just as we can with lists and arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in alphabet:\n",
    "    if letter in 'hello world':\n",
    "        print(letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <u>3. Summary Statistics</u><a id='stats'></a>\n",
    "\n",
    "Now that we have a way to collect data points in containers and create/use functions in Python, let's take a moment to put together everything we have learned so far to explore some basic statistical concepts! \n",
    "\n",
    "Suppose you are in a class with 14 other students and had recently taken an exam. You normally do quite well in the class, but you found this one to be particularly difficult - you ended up scoring **80.2%**, lower than your usual A-range scores. You wonder if you just hadn't studied well enough, or if your fellow high-achieving classmates struggled, too. \n",
    "\n",
    "In particular, you may be wondering:\n",
    "> *What was the average score for the class?*  \n",
    "> *What was the highest score?*  \n",
    "> *How did I do compared to the rest of the class?*\n",
    "\n",
    "These are great questions about the **distribution** - or shape - of data. We can get a good sense of what the data looks like with a set of statistics that summarize the distribtion of the data.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Run the cell below to create an array of your class's exam results:</b></span></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data - exam results of your class\n",
    "test_scores = np.array([80.2, 80.3, 72.1, 78.2, 69, 77.1, 74.1, 52.9, 72.9, 79.7, 82.2, 0.0, 78.1, 73.3, 78.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's answer one of the question right now, using a function we've seen before.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Q1: What was the highest score on the exam?</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out the highest score isn't that much higher than your score at all! But you are still wondering where you placed relative to your other classmates - is your score among the top 20% of exam scores? Put another way, did you score better than 80% of the students in the class? To answer this question, we will want to find its **percentile rank**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.1. Percentiles<a id='percentile'></a>  \n",
    "\n",
    "\n",
    "Values of a numerical data set have a **rank order** - in other words, data elements can be sorted in increasing order such that the value of data at a given rank is <u>greater than or equal to</u> the data value of the preceding rank. \n",
    "\n",
    "When working with data, it is often more informative to describe quantities in terms of percentages of the data. As example, earning the second highest score in a class with **100 other students** would seem more impressive than earning the second highest score in a class with **2 other students**. In the first scenario, you would have beat out 99 other students - in other words, **you would have scored higher than 99% of your classmates.** In the second scenario, you would have scored higher than just 1 other student - you would have scored higher than **50%** of your classmates.\n",
    "\n",
    "**These percentage values represent your percentile rank**: 99% in the first scenario; 50% in the second.\n",
    "\n",
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "The <b>percentile rank <i><code>p</code></i></b> of a value in a collection indicates that the value is greater than or equal to <b><i><code>p</code></i>%</b> of all other data points in the collection.\n",
    "</div>\n",
    "\n",
    "By definition, we can conclude that:\n",
    "* the **maximum** value has a **percentile rank of 100%**.\n",
    "* the **minimum** value of the data set can, but will **not necessarily, have a percentile rank of 0%**.\n",
    "\n",
    "Let's check this on our `test_scores` data. First, it may help to sort the test scores in ascending order - we'll use the NumPy array's `.sort()` function to do this. <span style='color:#4169E1'><b>Run the following 2 code cells:</b></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before sort\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after sort\n",
    "test_scores.sort()\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the data is sorted, we can understand the minimum value of the array as the left-most value in the array (index: 0) and the maximum value as the right-most value in the array (index: length-1).\n",
    "\n",
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Maximum:**  \n",
    "As we saw earlier, the highest score is 82.2. It is indeed the case that 100% of all other values in the data are less than or equal to 82.2. The percentile rank of 82.2 is in 100%.\n",
    "\n",
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Minimum:**  \n",
    "We also see that the lowest score is 0 (yikes!). In this example, the minimum value is unique, so it is the case that no other values are less than equal to the minimum in the data - it has a percentile rank of 0%. But what if there were multiple scores of 0 in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introducing 4 more scores of 0 to the data\n",
    "test_scores2 = np.append(np.repeat(0, 4), test_scores)\n",
    "test_scores2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum value is still 0. However, there are now four other 0's in the dataset, which means there are four other values in the array that are less than **or equal to** the minimum (index 0 of the array), or 22.2%. Thus, the percentile rank of the minmum value 0 for `test_scores2` is 22.2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# computing percentile rank\n",
    "4/(len(test_scores2)-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>You Try!</b> Let's go back to our class scores data, <code>test_scores</code>. <b>What is your percentile rank?</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Now we are equipped to define the concept of percentiles**! \n",
    "\n",
    "As data scientists assessing the distribution of data, we are usually more interested in looking at what the data values are at specific percentile ranks - not the other way around. The <u>data value</u> at a percentile rank of `p`% is called the <u>`p`th percentile</u>. \n",
    "\n",
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "Let <b><i><code>p</code></i></b> be a number between 0 and 100. The <b><u><i><code>p</code></i>th percentile</u></b> of a collection is the smallest <b><u>value</u></b> in the collection that is at least as large as <b><i><code>p</code></i>%</b> of all the values.\n",
    "</div>\n",
    "\n",
    "So, by definition we know that:\n",
    "1. the 0th percentile is equivalent to the **minimum** value\n",
    "2. the 100th percentile is equivalent to the **maximum** value\n",
    "3. the 50th percentile is equivalent to the **median** value\n",
    "\n",
    "We an use the `np.percentile()` and `np.median()` functions to verify the above statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "np.percentile(test_scores, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "np.percentile(test_scores, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "np.percentile(test_scores, 50) == np.median(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Quartiles**\n",
    "\n",
    "As we saw above, the **median** of the distribution is defined as the 50th percentile, such that 50% of the data ranks below, and the other 50% ranks above, the median value - put another way, it is the \"halfway point\" of the data and is one measure of the **center** of a distribution.\n",
    "\n",
    "It can also be referred to as the **second quartile**. The **first quartile** of a numerical distribution, you may have guessed, is the 25th percentile; and the **third quartile** is the 75th percentile. Finding the data's minimum, first quartile, median, third quartile, and maximum values together begin to give us a nice picture of what the data looks like - whether the data is spread out, if it is skewed, if it is concentrated around a certain range of values, etc.\n",
    "\n",
    "Let's find these values for our data with the `np.percentile()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(test_scores, [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the data values are gathered around the median, but that there is a noticeable **outlier** value of 0. While the median holds up well against outliers, we'll see how an outlier can heavily influence other summary statistics.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2. The Mean<a id='mean'></a> \n",
    "\n",
    "The mean is another measure of the center of a distribution. Its definition may be very familiar to you:\n",
    "\n",
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "The <b>average</b> or <b>mean</b> of a collection of numbers is the sum of all the elements in the collection, divided by the number of elements in the collection.\n",
    "</div>\n",
    "\n",
    "The NumPy functions `np.mean()` and `np.average()` return the mean of an array.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Find the mean</b> of the class test scores:</span></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **How does it compare to the median?**\n",
    "\n",
    "Whereas the median is calculated based on the rank, or position, of the values and therefore is quite indirectly dependent on each individual value, the mean is directly dependent on the values themselves. In our example, the outlier of 0 is having the effect of pulling the sum of the scores down quite significantly before the total is divided by the number of scores. The median, on the other hand, is not nearly as affected by the value of the minimum - even if we were to <span style='color:#F4BB44'>change the minimum value</span>, as long as the value is less than or equal to the current median value, <span style='color:navy'>the median will not change</span>:\n",
    "\n",
    "**Ex.**\n",
    "><code>array_A = [<span style='color:#F4BB44'><b>0</b></span>, 3, <span style='color:navy'><b>5</b></span>, 7, 7]</code>  \n",
    " <b>Median = <span style='color:navy'>5</span></b>  \n",
    " <b>Mean = <span style='color:#CC5500'>4.4</span></b>\n",
    "\n",
    "><code>array_B = [3, <span style='color:#F4BB44'><b>4</b></span>, <span style='color:navy'><b>5</b></span>, 7, 7]</code>  \n",
    " <b>Median = <span style='color:navy'>5</span></b>  \n",
    " <b>Mean = <span style='color:#CC5500'>5.2</span></b>\n",
    "\n",
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Visualizing Distributions**\n",
    "\n",
    "In this section we will use <a href='https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html'><b>matplotlib</b></a>, a comprehensive visualization library, to create plots of our distributions. Don't worry about the code for generating the plots - for now, let's use this as a tool to picture what the data looks like, and to visualize the relationship between the mean, median, and shape of the distribution. \n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Run the cell below</b> to create a <u>histogram</u> of our test scores data:</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "numBins = 50\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "ax.hist(test_scores, bins=numBins, density=True);\n",
    "ax.set_ylabel(\"density (% per score range)\");\n",
    "ax.set_xlabel(\"test scores\")\n",
    "ax.xaxis.set_ticks(np.arange(0, 100, 10))\n",
    "ax.set_title(\"Distribution of Test Scores\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "A <b>histogram</b> is a visualization of the distributions of a numerical variable. It looks like a bar plot, but it is different in a few key ways:    \n",
    "    \n",
    "- The horizontal (x) axis represents values captured in <u>equally spaced</u> ranges of values, called <b>bins</b>  \n",
    "- The vertical (y) axis measures the <b>density</b> of the value ranges. It captures how crowded the bins are <b>relative to the size of the bins</b> <br><i>&nbsp;&nbsp;&nbsp;It is important to note that it does <b>NOT</b> capture the percent of data that falls in each bin</i>\n",
    "- The proportion of data that falls in each bin is captured by the <b>area of the bar</b> or <code>y-value x bin width</code>\n",
    "  <br><i>&nbsp;&nbsp;&nbsp;Therefore, the total area of the histogram sums to 1.0 </i>\n",
    "    \n",
    "</div>\n",
    "\n",
    "The bin sizes used to group the scores are determined by the number of bins we want to create - the greater the number of bins the smaller the bin sizes, and, in our case, the finer the score ranges. If you are curious about the bin ranges used to creat our histogram above, run the cell below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score bins for our histogram\n",
    "binBounds = np.round(np.arange(0, np.max(test_scores)+1, np.max(test_scores)/numBins), 3)\n",
    "[binning for binning in zip(binBounds[:-1], binBounds[1:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value 0 certainly stands out as an anomaly in the data! There is another score in the low-50's that stands isolated from the bulk of the data, too. When one side streches out away from the bulk of the data, we say that the data is **skewed**. Our histogram, we can see, is **left-skewed**. \n",
    "\n",
    "When we have a skewed distribution, the mean tends to pull away from the median in the direction of the skew.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Let's mark the mean and median values</b> on the histogram, and see where they land: <span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "\n",
    "mean = np.mean(test_scores)\n",
    "median = np.median(test_scores)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "ax.hist(test_scores, bins=numBins, density=True);\n",
    "ax.set_ylabel(\"density (% per score range)\");\n",
    "ax.set_xlabel(\"test scores\")\n",
    "ax.plot(mean, -0.002, marker='^', color='#CC5500', markersize=9)\n",
    "ax.plot(median, -0.002, marker='^', color='navy', markersize=9)\n",
    "ax.xaxis.set_ticks(np.arange(0, 100, 10))\n",
    "ax.set_title(\"Distribution of Test Scores\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue triangle marks the median value, and the orange triange marks the mean. Remember that the <span style='color:navy'><b>median</b></span> marks the \"halfway point\" of the data - half of the data values lie below the median, and the other half above the median. If we measured the area of the bars to the left of the median, and the area of the bars to its right, we would find they are roughly 0.5 (50%) each. \n",
    "\n",
    "What about the <span style='color:#CC5500'><b>mean</b></span>? On the histogram, we can see that a majority of the data points are above the mean value.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<i class=\"fa fa-info-circle\" style=\"font-size:22px;color:orange\"></i> &nbsp;We can think of the mean as <b>the center of gravity or balance point of the histogram</b>. It may help to imagine the bars of the histogram as weights stacked on top of a balancing board. If we were to balance the histogram at a singular point of the board, where would we place the fulcrum? If placed near 80, the figure will tip to the left; if placed near 0, the figure will tip to the right. Somewhere in between is the point where the figure will balance - that point is 69.90666, the mean.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's balance the histogram:\n",
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "\n",
    "ax.hist(test_scores, bins=numBins, density=True);\n",
    "ax.set_ylabel(\"density (% per score range)\");\n",
    "ax.set_xlabel(\"test scores\")\n",
    "ax.xaxis.set_ticks(np.arange(0, 100, 10))\n",
    "ax.plot(np.mean(test_scores), -0.002, marker='^', color='#CC5500', markersize=9)\n",
    "# ax.plot(np.median(test_scores), -0.002, marker='^', color='navy', markersize=9)\n",
    "ax.plot([0, np.max(test_scores)], [0, 0], color='grey')\n",
    "ax.set_title(\"Distribution of Test Scores\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Symmetry**\n",
    "\n",
    "We can tell by looking at the histogram that the distribution of test scores is not symmetric - if we were to fold the histogram at its half-way point (the median), the shape of the two sides would not match. \n",
    "\n",
    "Most of the skew in our data is coming from the 2 lowest scores. Let's say that, upon investigating further, we find out that the two data points are in fact anomalies:\n",
    "- the student with a score of 0 had actualy dropped from the class, and\n",
    "- the student with a score of 52.9 was sent home during the exam for being sick, and was granted a re-take\n",
    "\n",
    "Since these scores will be dropped from the students' grades by the teacher, we will do the same and drop them from our analysis. What will the distribution look like now? Would it still have a skew, or is it now symmetric?  \n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Run the cell below to find out:</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores.sort() # making sure this is sorted\n",
    "test_scores_high = test_scores[2:]\n",
    "mean = np.mean(test_scores_high)\n",
    "median = np.median(test_scores_high)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "\n",
    "ax.hist(test_scores_high, bins=8, density=True);\n",
    "ax.set_ylabel(\"density (% per score range)\");\n",
    "ax.set_xlabel(\"test scores\")\n",
    "ax.plot(mean, -0.002, marker='^', color='#CC5500', markersize=9)\n",
    "ax.plot(median, -0.002, marker='^', color='navy', markersize=9)\n",
    "ax.xaxis.set_ticks(np.arange(0, 105, 10))\n",
    "ax.set_title(\"Distribution of Test Scores\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, notice that the mean and median values of the distribution are much closer together - they are off by only a couple of points! We can see that the distribution is also much more symmetric than before, but that there is still a slight left-skew. As we mentioned earlier, the skew is indicated not just by the shape of the histogram but by the direction the mean is pulled toward away from the median.\n",
    "\n",
    "You may already have arrived at this final point about the relationship between the mean and the median:\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<i class=\"fa fa-info-circle\" style=\"font-size:22px;color:orange\"></i> &nbsp;In general, for symmetric distributions, <b>the mean and median will be equal to one another</b>.\n",
    "</div>\n",
    "\n",
    "If a distribution is symmetric, there is no left- or right-skew that pulls the center of gravity away from the median; thus, the balancing point of the histogram - the mean - would land on the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.3. Standard Deviation<a id='stddev'></a>  \n",
    "\n",
    "The mean and median tell us where the center of the distribution is; and the distance between them can indicate a skew in the distribution or the existince of outliers. Another important detail about a distribution is **how spread apart the data points tend to be from the mean**. This measure of variability is captured by the **standard deviation**.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Run the cell below</b> to visualize three relatively symmetric distributions with the <u>same mean</u> but <u>different standard deviations</u>:</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "mean=np.mean(test_scores_high)\n",
    "print(\"Mean:\", mean)\n",
    "x1= np.random.normal(loc=mean, scale=2, size=50)\n",
    "x2= np.random.normal(loc=mean, scale=6, size=50)\n",
    "x3= np.random.normal(loc=mean, scale=12, size=50)\n",
    "\n",
    "fig, axs = plt.subplots(3, sharex=True, figsize=(6,7))\n",
    "axs[0].hist(x1, bins=15,  density=True)\n",
    "axs[0].axvline(mean, color='#CC5500', label=\"mean\")\n",
    "axs[1].hist(x2, bins=15, density=True)\n",
    "axs[1].axvline(mean, color='#CC5500', label=\"mean\")\n",
    "axs[2].hist(x3, bins=15, density=True);\n",
    "axs[2].axvline(mean, color='#CC5500', label=\"mean\")\n",
    "axs[2].set_xlabel(\"test scores\")\n",
    "axs[1].set_ylabel(\"density\")\n",
    "axs[0].set_title(\"Same mean, 3 different distributions!\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Calculating the Standard Deviation**\n",
    "\n",
    "Let's begin by dissecting how the measure of spread in the data is calculated. We'll use the `test_scores_high` data we created, which dropped the two anomalous cases from the data. \n",
    "\n",
    "*Note: We'll create a table to capture results of the steps along the way, but don't worry about the code for this for now - we will cover the topic of data frames and the Pandas library later in this notebook!*\n",
    "\n",
    "**Step 1.**  \n",
    "Since the standard deviation is a measure of roughly how far off the data points are from their mean, we'll need to calculate how far each value is from the mean. These values are called the **deviations from the average**, and are simply the data points minus the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. The deviations from average.\n",
    "mean = np.mean(test_scores_high)\n",
    "deviations = test_scores_high - mean\n",
    "print(\"Mean:\", mean)\n",
    "\n",
    "# ignore this ~~ creating table\n",
    "import pandas as pd\n",
    "calculation_steps = pd.DataFrame({\"Score\":test_scores_high, \"Deviations from Average\":deviations}, index=None)\n",
    "calculation_steps.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the deviations are negative; those correspond to values that are <u>below</u> average. Positive deviations correspond to values that are <u>above</u> average.\n",
    "\n",
    "**Step 2.**  \n",
    "To calculate roughly how big the deviations are, it is natural to want to compute the mean of the deviations. But something interesting happens when all the deviations are added together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will output 0 (or very, very close to 0, due to rounding error)\n",
    "np.sum(deviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive deviations cancel out the negative deviations! This is true of all lists of numbers, no matter what the histogram of the list looks like: **the sum of the deviations from average is zero**. And since the sum of the deviations is 0, the mean of the deviations will be 0 as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also 0 (or very, very close to 0)\n",
    "np.mean(deviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the mean of the deviations is not a useful measure of the size of the deviations. What we really want to know is roughly how big the deviations are, regardless of whether they are positive or negative. **We need a way to eliminate the sign of the deviations.**\n",
    "\n",
    "One way to get rid of signs is to take the square of the value. Let's do that here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. The squared deviations from average\n",
    "squared_deviations = deviations ** 2\n",
    "\n",
    "# ignore this ~~ updating table\n",
    "calculation_steps.loc[:,'Squared Deviations from Average'] = squared_deviations\n",
    "calculation_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.**  \n",
    "*Now* we can take the mean!\n",
    "\n",
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "The mean of the squared deviations is called the <b>variance</b> of the data values.    \n",
    "</div>\n",
    "\n",
    "Let's calculate the variance here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Variance\n",
    "\n",
    "variance = np.mean(squared_deviations)\n",
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.**  \n",
    "While the variance is a good measure of spread, it is not in the same scale as the original variable, since its units are the square of the original units. This makes interpretation very difficult, so we will return to the original scale by taking the square root of the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Square root of the Variance: the Standard Deviation\n",
    "standard_deviation = variance ** 0.5\n",
    "standard_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "We have just computed the <b>standard deviation (SD)</b> of the data values. The SD measures roughly how far the data values are from their average. It is defined as the <u><i>root mean square of deviations from average</i></u>.  \n",
    "</div>\n",
    "\n",
    "You can also use the function `np.std()` to compute the SD of values in an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(test_scores_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<i class=\"fa fa-info-circle\" style=\"font-size:22px;color:orange\"></i> &nbsp;Just like the mean, the standard deviation <b>is very sensitive to outliers</b> in the data. This highlights the importance of cleaning the data to rid of anomalous cases in order to extract meaningful information from these statistical analyses.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation before cleaning - original set of 15 scores:\n",
    "np.std(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Interpreting the Standard Deviation**\n",
    "\n",
    "So, where does your score land in the class distribution? We now have a language to describe how far away a single data point is away from the mean - <u>the number of standard deviations it is away from the mean</u>.\n",
    "\n",
    "First, calculate how different you score is from the class average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your score deviation from the mean\n",
    "80.2 - mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You scored 3.6 points higher than the class average of 76.6. The standard deviation is 3.75 points. You have scored almost 1 standard deviation higher than the class average:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(80.2 - mean)/standard_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be wondering why we like to talk about the spread of data in terms of the number of standard deviations from the mean. This is because **in <u>all numerical data sets</u> (!), a majority of the data values fall within a few standard deviations of the average\"**. In other words, we can rely on the fact that most of the data will be found within 3-4 SDs above and below the mean. When you say, \"I scored 3.6 points higher than the class average\", we don't quite know how good that result is. But when you say, \"I scored a standard deviation above the average\", we know that that is notably higher than the class average, because it is in the context of the distribution of scores. The <b>number of standard deviations</b> a specific data point is from the mean can tell us where we would expect that point to land on the histogram.\n",
    "\n",
    "For a more formal theorem, we look to what is called Chebychev's Bounds.\n",
    "\n",
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Chebychev's Bounds:</b><br>\n",
    "For any distribution of numbers <i>z</i> - no matter how irregular the distribution - the proportion of entries that are in the range \"average &plusmn; <i>z</i> SDs\" is at least $1-\\frac{1}{z^2}$. Specifically:\n",
    "    \n",
    "- the proportion in the range \"average &plusmn; <i>2</i> SDs\" is **at least** $1-\\frac{1}{2^2}=0.75$ \n",
    "- the proportion in the range \"average &plusmn; <i>3</i> SDs\" is **at least** $1-\\frac{1}{3^2} \\approx 0.89$ \n",
    "- the proportion in the range \"average &plusmn; <i>4.5</i> SDs\" is **at least** $1-\\frac{1}{4.5^2}\\approx0.95$ \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<i class=\"fa fa-info-circle\" style=\"font-size:22px;color:orange\"></i> &nbsp;The key phrase here is <b><i>at least</i></b> - it is very possible that 100% of the data will be captured within even 3 (or even fewer) SDs about the mean. You'll see below that this is the case in our data - most of the test scores lie within 1 SD of the class average, and amost entirely within 2 SDs of the class average. The theorem here provides a <u>lower bound</u> of the proportion of data that that will be captured within <code>z</code> standard deviations of the mean.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that, for any numerical distribution, the bulk of the data is always mostly contained (>= 89%) within 3 SDs of the mean, and almost entirely so (>=95%) within 5 SDs. In this context, the <b>higher the value of the SD</b>, the wider the range of values needs to be to capture \"most of the data\" (i.e. the range `[average - z*SD, average + z*SD]` widens &harr; as `SD` increases &uarr;), and thus indicate a wider spread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Standard Units**\n",
    "\n",
    "The quantiy *z* above measures *standard units*, or the number of standard deviations above the mean. It is common practice to **standardize the data**, such that data values are converted to standard units for purposes of analysis or modeling. Standardizing the data is an effective way to compare distributions of multiple fields of data with very different units of measure; and it is often leveraged as a data cleaning step for running machine learning models.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Run the cells below</b> to create a function for standardizing data, convert <code>test_scores_high</code> to standard units, and see how the distribution of standardized data compare to that of the original data. <b>What do you notice?</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. function to standardize data\n",
    "def standard_units(numbers_array):\n",
    "    \"Convert an array of numbers to standard units\"\n",
    "    return (numbers_array - np.mean(numbers_array))/np.std(numbers_array)\n",
    "\n",
    "# 2. standardize test_scores_high: # of SDs away from the mean\n",
    "standard_units(test_scores_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. plot the distributions of the original and standard units together\n",
    "\n",
    "plt.style.use('default')\n",
    "mean=np.mean(test_scores_high)\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(6,7))\n",
    "axs[0].hist(test_scores_high, bins=8,  density=True)\n",
    "axs[0].axvline(mean, color='#CC5500', label=\"mean\")\n",
    "axs[1].hist(standard_units(test_scores_high), bins=8, density=True);\n",
    "axs[1].axvline(0, color='#CC5500', label=\"mean\")\n",
    "axs[0].set_xlabel(\"test scores\")\n",
    "axs[1].set_xlabel(\"z scores\")\n",
    "axs[0].set_ylabel(\"density\")\n",
    "axs[1].set_ylabel(\"density\")\n",
    "axs[0].set_title(\"Original Units\", loc=\"left\")\n",
    "axs[1].set_title(\"Standard Units\", loc=\"left\")\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <u>4. More Data Structures</u><a id='struct'></a>\n",
    "\n",
    "In the previous sections, we looked at ways to store and work with a collection of data values within a sequence, like a list or an array. We also explored insights we can gain from computing summary statistics on those collections of data. Now we need a way to store and work with multiple separate collections of information about the same population - e.g. in addition to the test scores of the class, perhaps we also know the students' IDs, and results from one other exam they have taken in the past. In the remainder of this notebook, we will work with data structures that allow us to store multiple pieces of information, or **features**, about a population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Dictionaries<a id='dict'></a>\n",
    "\n",
    "We can use arrays to collect data points on a single feature of the population, like `test_scores`. When we have multiple arrays capturing different features of the same population, one way to store all of the different arrays is in a **dictionary**.\n",
    "\n",
    "Here are two examples of a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex1. dictionary of single values\n",
    "numerals = {'I': 1, 'V': 5, \"X\": 10}\n",
    "numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex2. dictionary of collections\n",
    "class_dict = {\"student_ID\":np.arange(1, len(test_scores)+1), \n",
    "              \"test_scores\":test_scores}\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "A <b>dictionary</b> organizes data into <b>key-value pairs</b>. This allows us to store and retrieve values indexed not by consecutive integers, but by descriptive keys. \n",
    "\n",
    "- <b>Keys:</b> Strings commonly serve as keys since they enable us to represent names of things. In the context of storing data, they are the column names, or names of the value(s) it represents. \n",
    "- <b>Values:</b> The data that we are storing. This can be a single value, or a collection of values. \n",
    "</div>\n",
    "\n",
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Accessing Dictionary Contents**  \n",
    "\n",
    "1. Access a dictionary value by indexing the dictionary by the corresponding key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. get value associated with \"test_scores\"\n",
    "class_dict['test_scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Dictionaries have methods that give us access to a list of its keys, values, and key-value pairs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a. list of dictionary keys:\n",
    "class_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## b. list of dictionary values:\n",
    "class_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## c. list of (key, value) pairs:\n",
    "class_dict.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<i class=\"fa fa-info-circle\" style=\"font-size:22px;color:orange\"></i> &nbsp; Unlike lists and arrays, dictionary are <b>unordered</b> so the order in which the key:value pairs appear in the dictionary may change when you run code cells. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Adding key-value Pairs** \n",
    "\n",
    "You can add a new item (key-value pair) into the exiting dictionary by assigning the value to a new name on the dictionary:\n",
    "\n",
    "```python\n",
    "dictionary['new_key'] = new_value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a new entry\n",
    "past_scores = np.array([89.0, 94.2, 78.0, 86.2, 81.2, 86.0, 88.3, 84.9, 88.1, 93.0, 82.2, 78.2, 96.1, 95.9, 98.2])\n",
    "\n",
    "class_dict[\"past_test_score\"] = past_scores\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_dict.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Note</b>: There can only be 1 value per key. If you attempt to assign a new value to the dictionary but specify a key name that already exists in the dictionary, the existing values associated with that key will be overwritten.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2. Matrices<a id='matrix'></a>\n",
    "\n",
    "Dictionaries organize information by features - all data values capturing student IDs are boxed into one container and saved into a dictionary; and data values about test scores from last year are boxed up into a separate container and saved into the dictionary under a differet label.\n",
    "\n",
    "But when you think about it, that is not the most helpful way to organize data when you are trying to **make predictions** about a specific case. For instance, say you were trying to guess what animal each record (row) is, given the following features:\n",
    "\n",
    "||Opposable Thumbs|Class of Animal|Diet |Tail Length |Number of Legs | Flies|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|**0**|True|Mammal|Bananas| long | 2|False|\n",
    "|**1**|False|Anthropod|Insects| none  |8| False|\n",
    "|**2**|False|Bird|Fish|short|2|False|\n",
    "\n",
    "We wouldn't want to look at the data one column at a time, the way dictionaries are organized, when we want to predict what animal record **0** might be. Instead, we'd want to look all the features of the one record at the same time:\n",
    "\n",
    "||Opposable Thumbs|Animal Class|Diet |Tail Length | Wings |Number of Legs | Flies|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|**0**|True|Mammal|Bananas| long | False | 2|False|\n",
    "\n",
    "To make a prediction about a particular record, we need to consider all its features - we want to organize information by record, not by column. This is exactly what a **matrix** is designed to do, and it is in this matrix form that we ultimately feed the data into machine learning models.\n",
    "\n",
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "    A <b>matrix</b> is a rectangular list*, or <b>a list of lists.</b> We say that matrix $M$ has shape $m \\times n$:\n",
    "    \n",
    "* It has **m** rows: each row is a list of all features that describe a single record;\n",
    "* It has **n** columns: each column is displayed as elements in the same position/index of every row, and represents a specific feature of the data\n",
    "\n",
    "</div>\n",
    "\n",
    "Our example above in matrix form would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_matrix = [[ True,    'Mammal', 'Bananas',  'long', 2, False],\n",
    "                 [False, 'Anthropod', 'Insects',  'none', 9, False],\n",
    "                 [False,      'Bird',    'Fish', 'short', 2, False]]\n",
    "\n",
    "animal_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to how the data would be represented in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_dict = {\"Opposable Thumbs\": [True, False, False],\n",
    "                \"Class of Animal\": ['Mammal', 'Anthropod', 'Bird'],\n",
    "                           \"Diet\": ['Bananas', 'Insects', 'Fish'],\n",
    "                    \"Tail Length\": ['long', 'none', 'short'],\n",
    "                 \"Number of Legs\": [2, 8, 2],\n",
    "                          \"Flies\": [False, False, False]}\n",
    "animal_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<i class=\"fa fa-info-circle\" style=\"font-size:22px;color:orange\"></i> &nbsp;*We use lists in this example to demonstrate what a matrix looks like, since the features are represented by different value types (and values in NumPy arrays must all be of the same type). However, NumPy's representation of the matrix <a href='https://numpy.org/doc/stable/reference/arrays.ndarray.html'><code>ndarray</code></a>, or the <b>n-dimensional array</b>, is usually preferred over using Python lists because NumPy arrays consume less memory and is able to handle operations much more efficiently than lists. Even though we have a mix of data types in our example, that does not mean we are stuck using lists. <b>There are many ways to transform categorical features of datasets into numerical features</b>; figuring out how best to handle categorical variables (like \"Diet\" and \"Animal Class\") is a big part of <b>data wrangling</b> for predictive modeling!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. <u>Pandas Library</u><a id='pd'></a>\n",
    "\n",
    "Now for the exciting part! Up to this point we have been fabricating data in the notebook to serve as our examples. With the introduction of the <b><a href='https://pandas.pydata.org/docs/user_guide/index.html'>Pandas Library</a></b>, we can **import** real data files into Jupyter Notebooks to explore. Let's do that now!\n",
    "\n",
    "<br>\n",
    "\n",
    "**Kaggle: our data source**  \n",
    "We will use the <a href='https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data'>\"Breast Cancer Wisconsin (Diagnostic) Dataset\"</a> from **Kaggle**. Kaggle is a data science competition platform that hosts datathons, publish datasets, and support an online community of data scientists. Anyone is able to download the cleaned, published datasets to explore from the site and have access to an abundance of resources - from **data dictionaries** that detail data contents, to notebooks and code that other users of the data have posted. It's a great place to find interesting problems to explore and learn from others who have done/are doing the same.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Pandas**  \n",
    "Pandas is the standard tool for working with **dataframes**. A dataframe is a data structure that that represents data in a 2-dimensional table of rows and columns. We've seen a couple of examples of dataframes already, in the section on standard deviations, and just now in the matrix section. They are very useful for exploratory data analysis, data cleaning, and processing before turning them into matrices to be fed into machine learning models.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'>We've already imported the <code>pandas</code> library, but <b>let's do that again here:</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5.1. Reading in the Data<a id='import'></a>\n",
    "\n",
    "Pandas allows us to easily \"read in\" data from a downloaded csv (comma separated values) file and save it as a variable in the Jupyter Notebook, with the `pd.read_csv()` function. It can take many different arguments depending on the desired specifications, but we can just accept the default for the optional parameters. The only required parameter is `filepath_or_buffer`, which asks for the **file path**, or location, of the data file on your computer so that it can find it and turn it into a Pandas dataframe. There are 2 ways to specify the file path:\n",
    "\n",
    "\n",
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Absolute File Path:** \n",
    "\n",
    "All of your files on the computer have a file path. If you go to the location of any file on your File Explorer, you can find its absolute file path by clicking the address bar at the top of the window. You'll see something like:\n",
    "\n",
    "<code>C:/Users/username/folder/data_folder/filename.csv</code>\n",
    "\n",
    "When you have all of the information needed to locate the file, all the way to the very first layer of folders, you have an <u>absolute</u> file path.\n",
    "\n",
    "\n",
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Relative File Path:**\n",
    "\n",
    "Your Jupyter notebook (ipynb) file that you are working on has a path, too. When you navigate from one folder to the next on the File Explorer, you often start at a file location (let's call that location A), back out of that folder, enter into another folder, and access the file in this new location (location B). We can do something similar with file paths, by specifying the path of location B **relative to** the location of A.\n",
    "\n",
    "Let's say this Jupyter notebook is found in location A, whose absolute path is:  \n",
    "<code>C:/Users/username/folder/myNotebook.ipynb</code>\n",
    "\n",
    "So, this is the **current directory**, or the location we are starting from:   \n",
    "<code>C:/Users/username/folder/</code>\n",
    "\n",
    "From here, we want to get to location B:  \n",
    "<code>C:/Users/username/folder/data_folder/filename.csv</code>\n",
    "\n",
    "<div class=\"alert alert-warning col-md-5 align=center\"><b>To do this, we can specify the relative path:</b><br>  \n",
    "<code>./data_folder/filename.csv</code></div> \n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "**Notation:**  \n",
    "- The **`.`** in the relative path indicates we are **staying in the same, current directory**. Since the `data_folder` that contains the desired file is **inside** the current directory we started out in, we indicate that it is from here that we then move into another folder, or identify a file to point to.\n",
    "<br>\n",
    "\n",
    "- The **`..`** indicates we need to **back out of the current folder**. It's the equivalent of clicking the back button on File Explorer.  \n",
    ">**Example**:  <br>\n",
    ">We can back out of multiple folders - say there is another file in this location we want to get to:\n",
    ">`C:/Users/another_user/theirFile.csv` \n",
    ">\n",
    ">We can access this from location A with the relative path:  \n",
    ">`../../another_user/theirFile.csv`\n",
    "\n",
    "\n",
    "Once we have the path, all we need to do it put it in string form, an input it as an argument!\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'><b>Run the code below</b> to read in our first dataset!</span></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using relative path!\n",
    "df = pd.read_csv(\"./data/data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset captures measurements and characteristics of breast mass (e.g. mass radius, smoothness, symmery) and the actual diagnosis of the mass. The challenge here would be to predict the diagnosis from the features of the mass. The purpose of this section is to introduce data manipulation using Pandas dataframes and series so we will not be tackling the challenge in this tutorial, but the notebooks uploaded on the <a href='https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data'>Kaggle page</a> would be a great place to see what other people have done with this dataset!\n",
    "\n",
    "---\n",
    "\n",
    "### 5.2. pd.DataFrame<a id='df'></a>\n",
    "\n",
    "The Pandas DataFrame data structure allows us to easily access both the rows (records) **and** columns (features). It can be created in many different ways: from scratch, from a dictionary of values, from a matrix, from reading in a dataset, etc.\n",
    "\n",
    "\n",
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp;**From scratch**:  \n",
    "\n",
    "Below is an empty DataFrame object - it has no column or row yet. Run the code to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fromScratch = pd.DataFrame()\n",
    "df_fromScratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a column to the dataframe in the same way that we can add new key-value pairs to dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fromScratch['first_column'] = np.arange(1, 10)\n",
    "df_fromScratch['second_column']= np.arange(9, 0, -1)\n",
    "df_fromScratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, once one column of a certain **length** is added to a dataframe, all other new columns must be of the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will throw an error\n",
    "df_fromScratch['short_column'] = np.array([7, 8, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **From a dictionary:**  \n",
    "\n",
    "We can also convert a dictionary of data into a Pandas DataFrame, as long as the the number of elements captured in each dictionary value is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animal dictionary from earlier\n",
    "pd.DataFrame(animal_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **From a matrix:**  \n",
    "\n",
    "..and same with matrices. Since a matrix does not have a name value like dictionaries do, we can include an argument to specify the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = ['Opposable Thumbs', 'Class of Animal', 'Diet', 'Tail Length', 'Number of Legs', 'Flies']\n",
    "pd.DataFrame(animal_matrix, columns = columnNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Exploring data contents:**  \n",
    "\n",
    "Let's explore the Pandas capabilities using breast cancer data we read in earlier. The first step we'd want to take when exploring a dataset is to undertand what the dataset contains. The DataFrame object has many attributes to help us with this task:\n",
    "\n",
    "1. Identify the number of rows (records) and columns (features) in the data\n",
    "2. Get info on the column names, their position on the dataframe, how many non-**null\\*** values there are in each feature, and what the data type of each feature is\n",
    "3. Get a list of the columns in the dataset\n",
    "4. Create a table of summary statistics on all numeric features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. find the number of rows and columns (row, col) in the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. summary of features\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. list of column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. summary statistics of numeric features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<i class=\"fa fa-info-circle\" style=\"font-size:22px;color:orange\"></i> &nbsp;A <b>null</b> or <b>nan</b> value represents an unknown or missing value in the data - it is an empty entry. If a feature is riddled with missing values, we may need to drop the feature from the investigation since it may not capture enough valid data, or the valid data it does capture may be biased. If a feature has some missing values but still captures valuable information, we will want to clean the data so to replace these values with something more interpretable. We won't touch on this here, but you can find a <a href='https://pandas.pydata.org/docs/user_guide/missing_data.html'>guide on how to work with missing data using Pandas</a> in their documentation.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp;**Selecting a DataFrame feature - Series**:  <br>\n",
    "\n",
    "We know from the `.info` output above that there is only one non-numeric field in the dataset, and that is the target variable - the diagnosis. Let's understand this target variable better.\n",
    "\n",
    "We can select a feature from the DataFrame in a similar way to how we would get the value of a dictionary - by indexing the dataframe by the column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data values of `diagnosis` column\n",
    "df['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted column is stored in a Pandas data structure called a **Pandas Series**. \n",
    "\n",
    "<i class=\"fa fa-book\" style=\"font-size:20px;\"></i> &nbsp;**Definition:**\n",
    "<div class=\"alert alert-success\">\n",
    "    A <b>Series</b> is a Pandas data structure that behaves very similarly to NumPy arrays and will be a valid argument to most NumPy functions. Series are also similar to dictionaries, in that its values can have index labels and be indexed by these labels.\n",
    "</div>\n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an array\n",
    "array_a = np.arange(1, 6)\n",
    "\n",
    "# this is a Series, with non-numeric index labels, and a name\n",
    "series_a = pd.Series(array_a, index=['a', 'b', 'c', 'd', 'e'], name=\"Series_A\")\n",
    "\n",
    "print(\"array: \", array_a)\n",
    "print(\"\\nSeries: \")\n",
    "print(series_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`series_a` has non-numeric indices. If I want to extract a value from the structure, I can index using its positional index (like an array), or using its label index (like a dictionary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting value like an array\n",
    "series_a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extracting value like a dictionary \n",
    "series_a['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Series can also have a `name` attribute, which is how Pandas knows to name the dataframe when a Series object is turned into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_a.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now back to our data.** If we were to predict the diagnosis based on the cancer mass attributes, it would be good to know how many categories of diagnoses there may be. We want to find the unique values of the variable.\n",
    "\n",
    "Like the DataFrame object, the Pandas Series object also has many useful attributes. Let's use a couple of them here to better understand the field:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all unique values of the field\n",
    "df['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 2 possible values for the `diagnosis` variable - malignant (`M`) and benign (`B`). Use the `.value_counts()` method to count how many of each are in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp;**Creating a dataset with fewer selected features:**  <br>\n",
    "\n",
    "Often times we want to investigate just a couple of fields from the data. In these cases, we may want to create a smaller dataset for greater efficiency and run times. We can select fields to keep in a few ways:\n",
    "\n",
    "**1. Double square brackets `[]`**  \n",
    "We can index the dataframe with a list of column names to create a dataset with just those columns (but with all the rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['diagnosis', 'area_mean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. `.loc[]` attribute**   \n",
    "We can do the same using the `.loc` attribute. This method allows us to specify the column names to keep **and** filter the rows at the same time.\n",
    "\n",
    "Just as we could slice (extract specific ranges of) sequences based their positional indices, we can slice the data rows and data columns by their index labels. \n",
    "\n",
    "The `.loc[]` method takes two ranges. The range for rows is specified first, and the range for columns second: \n",
    "\n",
    "df.loc\\[ <span style='color:green'>startRowLabel<b> : </b>endRowLabel</span>, <span style='color : navy'>startColName<b> : </b>endColName</span> \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabs all records, and all columns positioned between and including `diagnosis` and `area_mean`\n",
    "df.loc[:, \"diagnosis\":\"area_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we just want the 2 columns and not the columns in between, we leverage the double-bracket\n",
    "df.loc[:, [\"diagnosis\",\"area_mean\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. `.iloc[]` - attribute**  \n",
    "This is very similar to `.loc[]`, but instead of using row and column labels, we specify index positions instead. We can see below that `diagnosis` is found at index `1`, and `area_mean` at index `5`. So, if we specify the range `1:6`, we should get the same table as before.\n",
    "\n",
    "*Remember that, when slicing with indices, the `stop` value in the `start`:`stop` range is excluded from the selection.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to see column positions\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing using index positions\n",
    "df.iloc[:, 1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, [1, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp;**Slicing and Filtering Dataset Records:**  <br>\n",
    "\n",
    "Just as we can create data with subsets of columns, we can create data with subsets of rows.\n",
    "\n",
    "**1. Regular indexing**  \n",
    "When we specify a range of integer values, DataFrames know to slice the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep first 100 records\n",
    "df[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Filtering by criteria**  \n",
    "We can also filter by a criteria in the data. For instance, what if we only wanted to check out the distributions of features for masses that are known to be \"benign\"? We would create what we call a **mask**, and apply it to the dataset, like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying a mask to the dataset\n",
    "# to only keep records that are benign\n",
    "df[df['diagnosis']=='B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a Series acts very much like a NumPy array. This mean that the expression `df['diagnosis']=='B'` would create a long array of `True` and `False`, depending on whether the element in the `diagnosis` field is `=='B'` or not. This sequence of boolean values acts as a mask on the dataset - the DataFrame knows only to keep records that contains a `True` value from the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask\n",
    "df['diagnosis']=='B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. `.loc[]` and `.iloc[]` attributes** \n",
    "\n",
    "The `.loc[]` attribute supports slicing and filtering rows, as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing rows using index values (which in this case is same as index positions)\n",
    "df.loc[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about `.loc[]` is that it allows you to filter or slice for rows and columns at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for benign records\n",
    "df.loc[df['diagnosis']=='B', 'diagnosis':'area_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also slice rows and columns simultaneously with the `.iloc[]` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:100, [1, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Feature Engineering & Applying Functions**:  <br>\n",
    "\n",
    "Often, we will want to engineer new features from existing ones or transform features in the dataset. We'll approach this in a couple of ways:\n",
    "\n",
    "1. Computing a new sequence of data with existing ones, and assigning it as a new column\n",
    "2. Using the `.apply()` DataFrame method\n",
    "\n",
    "**1. Creating a new potential feature**\n",
    "\n",
    "Looking at the available fields, it looks like there might be an opportunity to approximate how *irregularly shaped* a mass may have been. In particular, we are interested in these data fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.loc[:, ['area_worst', 'radius_worst', 'perimeter_worst', 'symmetry_worst', 'diagnosis']]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the area of a circle is found by the equation $A = \\pi r^2$, and that the circumference of a circle is given by $C = 2 \\pi r$. If we make the assumption that the mass is **not** irrecgularly shaped, i.e. the mass has a circular shape, then the measured perimeter of the mass and the calculated circumference should in theory be pretty similar. If the perimeter is larger than the circumference by a lot, that may be a good indicator that there is irregulary in the shape, which may be a good predictor of a malignant mass.\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'>Let's <b>calculate the circumference of the mass</b> given its measured area and radius, and create a new field that captures the <b>ratio of the calculated circumference to the measured perimeter:</b></span></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series behave like NumPy arrays - the same rules of arithmetic operations apply here\n",
    "\n",
    "# C = 2*A/r : circumference = 2 x area / radius\n",
    "circumference = 2*df_new['area_worst']/df_new['radius_worst']\n",
    "\n",
    "# creating the new ratio field\n",
    "df_new['ratio_CtoP'] = circumference / df_new['perimeter_worst']\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We have engineered our first feature.\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. `.apply()`**  \n",
    "\n",
    "`.apply` allows us to take a function and apply it to the Pandas series or dataframe. \n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'>Let's <b>standardize the columns <code>area_worst</code>, <code>radius_worst</code>, and <code>perimeter_worst</code></b> by applying the function we had defined earlier:</span></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the docs for more details!\n",
    "df.apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to standardize data\n",
    "def standard_units(numbers_array):\n",
    "    \"Convert an array of numbers to standard units\"\n",
    "    return (numbers_array - np.mean(numbers_array))/np.std(numbers_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the function to the 3 fields\n",
    "df.loc[:, ['area_worst', 'radius_worst', 'perimeter_worst']].apply(standard_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..so much more elegant than extracting each individual field as a Series, plugging them into the function, and setting each new output a as a new column in the dataset!\n",
    "\n",
    "<br><i class=\"fa fa-thumb-tack\" style=\"font-size:16px;\"></i>&nbsp; **Grouping Data**:  <br>\n",
    "The final concept we will cover is the concept of **grouped operations**. Grouping datasets allow us to efficiently compute and compare aggregations of data values conducted separately for each group of fields.\n",
    "\n",
    "In the section above, we have just explored shape irregularity as a possible predictor of malignant vs. benign masses. One way to analyze whether we may be onto something is to compute the feature's summary statistic separately for the two groups, and see if we observe a notable difference. We can do this with the `.groupby()` method for Pandas DataFrames, which organizes the data into groups based on the values of the group-by variable, and computes an aggregation on the members of each group such that we are left with an aggregate value for each group. It takes the form:\n",
    "\n",
    "`df.groupby(group_variable).aggregation()`\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"><span style='color:#4169E1'>Let's <b>find the averages by diagnosis</b> of the new and existing features in the <code>df_new</code> data:</span></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.groupby('diagnosis').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Sources**\n",
    "\n",
    "Composing Programs: https://www.composingprograms.com/  \n",
    "UC Berkeley Data 8 Textbook :https://inferentialthinking.com  \n",
    "UC Berkeley Data Science Education Program - Modules: https://github.com/orgs/ds-modules/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
